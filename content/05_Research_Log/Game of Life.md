---
title: 2025-07-07 â€” Untitled
date: 2025-07-07
tags:
  - log
draft: true
---

The **Game of Life**, created by John Conway, is a zero-player cellular automaton where simple rules can produce complex, lifelike behavior. It operates on a grid of cells that are either **alive** or **dead**, and they evolve over time based on the state of their neighbors.

The **Game of Life** is a cellular automaton on a 2D grid. Each cell is:

- `alive (1)` or `dead (0)`
    
- At each time step (generation), each cell updates according to **4 rules**:
    

|State|Rule (Based on 8 neighbors)|Result|
|---|---|---|
|Alive|< 2 live neighbors â†’ dies (underpop)|Dies|
|Alive|2 or 3 live neighbors â†’ stays alive|Lives|
|Alive|> 3 live neighbors â†’ dies (overpop)|Dies|
|Dead|Exactly 3 live neighbors â†’ becomes alive|Born|



## Patterns That "Feel Alive"

| Type             | Feels like...            | Key Example              |
| ---------------- | ------------------------ | ------------------------ |
| Oscillators      | Metabolism/heartbeat     | Blinker, Pulsar          |
| Spaceships       | Locomotion               | Glider, LWSS             |
| Glider Guns      | Reproduction             | Gosper Glider Gun        |
| Breeders         | Exponential growth       | Rakes, Switch Engine     |
| Self-Replicators | Autopoiesis              | Gemini, Demonoid         |
| Logic Machines   | Cognition or computation | Universal Turing Machine |

#### **Infinite growth and persistence:**

There **are** known structures that grow forever, e.g.:

- **Glider guns**: e.g., Gosperâ€™s glider gun produces endless gliders.
    
- **Breeders / Rakes**: Emit glider guns or puffers over time, which in turn emit gliders.
    
- **Self-replicators**: Like _Gemini_ (by Andrew J. Wade), which rebuilds itself while moving diagonally.
    
- **Puffer trains**: Leave debris behind and continue moving indefinitely.
    

These are **not static**, and **always have movement**, but are **not immune to interference**â€”if you add random cells, you can disrupt or destroy them.

However, researchers have explored:
- **Life "ecologies"**: Some chaotic infinite patterns stabilize into â€œorganismsâ€ that persist for long periods and interact.
    
- **Debris fields + glider farms**: Large areas where new patterns (even if added randomly) are often â€œabsorbedâ€ or â€œeaten upâ€ by the system. Not immune, but resilient.

In addition, there are **autopoiesis** or **life-like** behavior. Some examples:

- **Demonoids**: Self-replicating spaceships that can rebuild themselves after part destruction.
    
- **Recursive logic-based constructions**: These simulate computation and can be designed to rebuild themselves if damage is minor and localized.
    
- **Metacells**: Structures made to act like individual cells in a "Life within Life" simulation (e.g., **OTCA metapixel**).

### A **Life ecology**

A **Life ecology** is a _region_ in the Game of Life that:

- **Contains many semi-stable patterns** (oscillators, puffers, gliders, etc.)
    
- **Keeps changing** but doesn't freeze or vanish
    
- Can _absorb or react to new input_ (gliders, noise)
    
- Behaves like a living ecosystem: **organisms emerge**, interact, sometimes die, sometimes persist

To create a **living ecology**, you combine:

|Component|Description|
|---|---|
|**Glider guns**|Emit motion and new data â€” base of activity|
|**Puffers**|Leave junk trails â€” build up debris|
|**Still lifes**|Make the region stable and absorb chaos|
|**Oscillators**|Periodically interact with incoming motion|
|**Rakes**|Move while leaving gliders behind|
|**Random noise**|(Optional) triggers unpredictable behavior|

### Design idea

Imagine a world where:

- One part is a **glider factory**
    
- Another part is a **puffer colony** slowly expanding
    
- Random interactions (or added noise) create **new emergent behaviors**
    

These systems aren't truly immune to perturbation, but:

- There is **never a still state**
    
- **Liveliness continues**, even with minor interventions


### p5.js IMPLEMENTATION PLAN

- Set up a 2D grid (`cols x rows`)
    
- Add a **2D array** to store current state
    
- Implement **Game of Life rules**
    
- Place known patterns like **Gosper Glider Gun**
    
- Animate it with `draw()`


[Golly](https://sourceforge.net/projects/golly/)
[Web Golly](https://golly.sourceforge.io/webapp/golly.html)
[Life Lexicon](https://conwaylife.com/ref/lexicon/lex_home.htm)





### Playing Conway Life with AI

- **Human** places a live cell manually whenever they want.
    
- **AI**: Places one live cell **in response**, associates with humanâ€™s approach(more on this later) but **diverging slightly** to guide the world toward:
	- Continuity (avoid stagnation/death)
	- Variation (avoid repetition, encourage novel formations)
    
- The **Game of Life** runs continuously (automated ticking).
    
- If the grid becomes static or dies out, **nothing resets** unless the **user chooses to restart**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   user clicks    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ p5.js client â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  FastAPI API â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚   (actor)    â”‚
        â–²                         â”‚              â”‚
        â”‚   JSON grid snapshots   â”‚              â”‚
        â”‚                         â”‚              â”‚
        â”‚                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚        enqueue experience      â”‚
        â”‚                                â–¼
        â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   new weights (.pt)     â”‚ Train worker â”‚  (learner)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚ (async proc) â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

- **Actor** â€“ the FastAPI server your players talk to.
    
- **Learner** â€“ a separate Python process that **reads gameplay logs**, improves the model every N seconds, and **drops a fresh `best_model.pt`**.
    
- **Hot swap** â€“ the actor sees a new file, loads it instantly, and continues serving with the upgraded brain.


#### Folder / file map
```
life_ai/
â”œâ”€ backend/
â”‚  â”œâ”€ model.py          # PyTorch network definition
â”‚  â”œâ”€ life.py           # Conway rules
â”‚  â”œâ”€ evolution.py      # training script âœ”
â”‚  â”œâ”€ api.py            # FastAPI server âœ”
â”‚  â””â”€ grid_state.npy    # saved grid (auto-created)
â”‚  â””â”€ replay.py
â”‚  â””â”€ learner.py
â””â”€ frontend/
   â”œâ”€ index.html
   â””â”€ sketch.js         # p5.js code âœ”

```


## Set up Python workspace

| Step | Command                                                                       | Why                                       |
| ---- | ----------------------------------------------------------------------------- | ----------------------------------------- |
| 2-1  | `cd life_ai`                                                                  | enter project                             |
| 2-2  | `python -m venv venv`                                                         | isolate dependencies                      |
| 2-3  | `source venv/bin/activate` _(mac/Linux)_  <br>`venv\Scripts\activate` _(Win)_ | activate venv                             |
| 2-4  | `pip install torch numpy fastapi uvicorn pydantic`                            | minimal packages: model, math, API server |

## Add the core code (copy-paste if not already present)

| File                       | Purpose                                                                                                                                                                                     |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`backend/life.py`**      | vectorised Conway â€œtickâ€ function                                                                                                                                                           |
| **`backend/model.py`**     | `LifeNet` neural net definition (GRID default = 32)                                                                                                                                         |
| **`backend/evolution.py`** | **offline neuro-evolution trainer** that produces `best_model.pt`<br><br>Replace the **fitness function** with a **novelty + optional quality** function. Maintain a small archive list.    |
| **`backend/api.py`**       | FastAPI server:  <br>â€¢ persistent grid  <br>â€¢ user â†’ AI move  <br>â€¢ background ticker  <br>â€¢ hot-swap model loader                                                                          |
| **`backend/replay.py`**    | in-memory â†’ disk logger (experience buffer)                                                                                                                                                 |
| **`backend/learner.py`**   | **online learner**: reads buffer every 60 s, fine-tunes weights, atomic save<br><br>Give each stored experience a _novelty reward_ instead of (or in addition to) the â€œcells-aliveâ€ reward. |

_(All snippets were supplied earlier; paste them verbatim into matching files.)_

##### How we designed the simple replay in `replay.py`

|Element|Implementation choice|Why we picked it|
|---|---|---|
|**RAM queue (`queue.Queue`)**|Limited to 10 000 items|Fast, thread-safe, prevents memory blow-ups.|
|**Background flusher thread**|Dumps the queue to `experience.pkl` every 30 s|Makes disk I/O non-blocking for the actor; file write is atomic enough for small blobs.|
|**Pickle format**|`pickle.dump(list_of_items, file)`|Easiest Python-native serialization for NumPy arrays.|
|**Rotation guard (optional)**|Delete / rename file when it exceeds e.g. 200 MB|Keeps disk usage bounded after months of uptime.|

> **One record** = `{"state": grid_copy, "action": (ax, ay), "reward": 0}`  
> (~4 â€“ 5 KB with a 32 Ã— 32 grid)

The learner later opens the file, **samples** a batch (e.g. 256 random records), computes a reward for each, and runs one gradient step.


##### How we designed the learner script

1. **Reads yesterdayâ€™s diary pages** (the `experience.pkl` file).
    
2. **Turns each page into training data**:
    
    - â€œHere was the gridâ€â€ƒâ†’â€ƒ**input** to the network.
        
    - â€œHereâ€™s the square the AI pickedâ€â€ƒâ†’â€ƒ**target** the network should rate highly **next time**.
        
    - â€œHow good was that move?â€â€ƒâ†’â€ƒ**weight** telling gradient-descent how strongly to learn from this page.
        
3. Runs one mini-batch of **gradient-descent** (the basic learning step of neural networks).
    
4. Saves the new weights in `best_model.pt`, so the FastAPI server hot-reloads them.
    

Originally â€œhow goodâ€ was measured only by **quality** (how many cells were still alive after a few ticks).  
Now we want to **blend in or even replace that with â€œnoveltyâ€**â€”how different the resulting pattern is from anything weâ€™ve ever seen.

## Front-end scaffold

|File|Purpose|
|---|---|
|**`frontend/index.html`**|loads p5.js & your sketch|
|**`frontend/sketch.js`**|draws grid, polls `/grid`, POSTs `/user_move` on clicks|

Start a static server in that folder:

`npx http-server -c-1 .`

_(`-c-1` disables caching for instant updates.)_

## First offline training pass (bootstrap brain)

|Step|Command|Why|
|---|---|---|
|5-1|`python backend/evolution.py`|evolves 2 000 generations (â‰ˆ 15 min on CPU)|
|5-2|Confirm `backend/best_model.pt` exists|required for API startup|

> _Training once gives the system a â€œgood enoughâ€ seed so gameplay isnâ€™t random on day 1. Later the learner keeps improving it online._

## Launch the always-on services

|Terminal #|Command|Role|
|---|---|---|
|**1**|`uvicorn backend.api:app --reload`|**Actor** â€“ serves API & life ticker|
|**2**|`python backend/learner.py`|**Learner** â€“ continuous on-line updates|
|_(optional)_|Use **pm2/systemd** instead of bare shells|auto-restart on crashes / reboots|

Hot-swap logic in `api.py` automatically reloads new weights whenever `best_model.pt` timestamp changes (milliseconds, no downtime).

## Open the playground

1. Browse to the address printed by `http-server` (often `http://127.0.0.1:8080`).
    
2. Click any empty cell â†’ your blue cell appears, then AIâ€™s reply, grid immediately ticks forward.
    
3. Leave the page open; watch patterns change as the learner silently improves the model every minute.

## Manual controls

|Action|How|
|---|---|
|Restart from scratch|Browser console â†’ `fetch('http://localhost:8000/restart',{method:'POST'})`|
|Inspect live grid JSON|`GET http://localhost:8000/grid`|
|Change tick speed|Adjust `await asyncio.sleep(0.2)` in `ticker()` (API)|
|Bigger board / smarter AI|Raise `GRID`, `POP`, `GENS` in `model.py` & `evolution.py`; retrain offline|

| Data item                           | Why we keep it                                                           | Typical size (32 Ã— 32 board)          | Growth pattern                        | Easy containment strategy                                                          |
| ----------------------------------- | ------------------------------------------------------------------------ | ------------------------------------- | ------------------------------------- | ---------------------------------------------------------------------------------- |
| **`grid_state.npy`**                | The _current_ Game-of-Life board so the world survives crashes / reboots | 32 Ã— 32 bytes â‰ˆ **1 KB**              | Constant (over-written every tick)    | Nothing to worry about â€“ it never grows.                                           |
| **`best_model.pt`**                 | Latest neural-net weights the actor loads                                | ~60â€“120 KB for a small MLP            | Over-writes in-place at every save    | Also constant. Keep only the newest file.                                          |
| **Experience log `experience.pkl`** | Raw â€œstate + actionâ€ records that the online learner studies             | One record â‰ˆ 4â€“5 KB (grid + metadata) | **Appends forever** if you do nothing | 1. Cap the in-RAM queue (already `maxsize=10 000`).<br>2. Rotate or trim the file. |
| **Server / learner stdout logs**    | Debugging information                                                    | 1â€“2 MB per day with default prints    | Linear per day                        | Pipe through `logrotate` or have PM2/systemd rotate logs.                          |

#### About MLP vs. CNN

### MLP
A plain **multilayer perceptron (MLP)** with two hidden layers (256 â†’ 256)
```
grid (32Ã—32 = 1 024 numbers â†’ flatten)
        â†“
Linear layer (1 024 â†’ 256) + ReLU
        â†“
Linear layer (256 â†’ 256)  + ReLU
        â†“
Linear layer (256 â†’ 1 024) + Sigmoid
        â†“
probability for every empty square

```
Total parameters: â‰ˆ 525 k â†’ < 1 MB on disk, < 3 MB RAM.

### CNN

**CNN (Convolutional Neural Network)** has special â€œfiltersâ€ (like visual sensors) that scan across the grid to find patterns.

These filters have:

- **Structure**: A specific size (like 3Ã—3) and fixed roles (e.g., edge detector)
    
- **Shared weights**: The same filter is used everywhere
    

ğŸ‘‰ This is what makes CNN **great for spatial pattern recognition**, but...

ğŸ‘ **Harder to evolve**:

- Filters must maintain their **spatial meaning** (e.g., detecting â€œglider tailâ€)
    
- Randomly mutating CNN filters often breaks their function
    
- Evolution algorithms must **respect the structure** of the filters and layers, or the network stops working
    

So CNNs are **not as mutation-friendly** unless you use smart evolution methods (e.g., NEAT, genetic CNNs).

| Feature                        | MLP                                | CNN                                        |
| ------------------------------ | ---------------------------------- | ------------------------------------------ |
| ğŸ² Easy to evolve randomly     | âœ… Yes (simple weights)             | âŒ No (filters are structured, fragile)     |
| ğŸ“ Easy to fine-tune with SGD  | âœ… Yes                              | âœ… Yes                                      |
| ğŸ§  Understand spatial patterns | âŒ Not really (needs more training) | âœ… Yes (designed for it)                    |
| ğŸŒ€ Pattern diversity           | âŒ Often collapses to repetition    | âœ… Encourages gliders, chaos, local effects |
| ğŸ‘¨â€ğŸ”§ Structural flexibility   | âœ… Any shape, mutate freely         | âŒ Filters must stay well-formed            |
## How it compares to other choices

| Candidate model                                                 | Pros for Conway life                                                                          | Cons in _your_ setting                                                                          | Verdict here                                                    |
| --------------------------------------------------------------- | --------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **Our MLP (baseline)**                                          | âœ” One file, <1 MB  <br>âœ” Fast CPU inference (â‰ˆ 0.5 ms)  <br>âœ” Mutation-friendly (neuro-evo)   | â€“ No built-in notion of â€œneighborsâ€  <br>â€“ Parameter count grows **O(NÂ²)** with board size      | _Best for â‰¤ 64Â² boards and quick iteration._                    |
| **Convolutional net (CNN)**                                     | âœ” Captures local patterns (blinkers, gliders)  <br>âœ” Parameter count â‰ˆ constant vs board size | â€“ Slightly more code  <br>â€“ Online gradient steps need careful LR tuning                        | _Great upgrade if you move to 128Â² or 256Â²._                    |
| **Graph neural net (GNN)**                                      | âœ” Naturally models cell adjacency                                                             | â€“ Heavy libraries (PyTorch Geometric)  <br>â€“ Slower per step                                    | _Overkill for a regular grid._                                  |
| **Transformer**                                                 | âœ” Global receptive field, good for large grids                                                | â€“ Millions of params  <br>â€“ Needs GPU for real-time                                             | _Not worth it unless you research scaling laws._                |
| **Tree search / Monte-Carlo (no NN)**                           | âœ” No training, only simulation                                                                | â€“ CPU cost explodes with board size  <br>â€“ No â€œmemoryâ€ (doesnâ€™t learn from past)                | _We used brute-force only as fallback._                         |
| **Reinforcement-learning (policy gradient) with CNN back-bone** | âœ” Learning signal tied directly to reward                                                     | â€“ More code (advantages, baselines)  <br>â€“ Susceptible to catastrophic forgetting online        | _Good future step once basics feel solid._                      |
| **Evolution-only, no gradients**                                | âœ” Dead-simple  <br>âœ” Embarrassingly parallel                                                  | â€“ Needs many rollouts â†’ CPU hours  <br>â€“ Harder to do tiny incremental updates while users play | _We hybridized: evo for bootstrap, SGD for online fine-tuning._ |

You can combine the benefits:

> Use a **shallow CNN encoder** (2â€“3 conv layers) to extract spatial features â†’ then flatten and pass to a **small MLP head** to score all grid positions.

This gives:

- ğŸ¯ Spatial awareness (via CNN)
    
- ğŸ§© Whole-board heatmap output (like MLP)
    
- ğŸ§  Easier mutation/fine-tuning (because head is MLP)


To build or customize LifeNet, start here:

|Stage|What to study|Free, up-to-date resource|
|---|---|---|
|1â€ƒPython & NumPy basics|Arrays, matrix math (youâ€™ll use them in `life.py`)|_Any Python intro_ or **fast.ai Lesson 1 notebooks** [course.fast.ai](https://course.fast.ai/Lessons/lesson1.html?utm_source=chatgpt.com)|
|2â€ƒWhat an MLP is|Neurons â†’ layers â†’ activations (MLP handles whole-board planning)|DataCampâ€™s guide to **multilayer perceptrons** [datacamp.com](https://www.datacamp.com/tutorial/multilayer-perceptrons-in-machine-learning?utm_source=chatgpt.com)|
|3â€ƒWhat a CNN is|Detect local patterns in images (CNN helps LifeNet "see" human moves)|CNN visual intro by **Victor Zhou** victorzhou.com|
|4â€ƒPyTorch fundamentals|Tensors, `nn.Module`, forward pass, loss, optimiser|PyTorch "Learning with Examples" tutorial [docs.pytorch.org](https://docs.pytorch.org/tutorials/beginner/pytorch_with_examples.html?utm_source=chatgpt.com) + Daniel Bourkeâ€™s hands-on crash course [youtube.com](https://www.youtube.com/watch?v=LyJtbe__2i0&utm_source=chatgpt.com)|
|5â€ƒBuilding small nets in practice|Combine CNN + MLP layers, use `torch.save`, modular design|DataCamp: â€œHow to learn PyTorch in 2025â€ [datacamp.com](https://www.datacamp.com/blog/how-to-learn-pytorch?utm_source=chatgpt.com)|
|6â€ƒNeural nets + Game of Life|Evolving Life patterns with nets â€” how AI learns to play Life|Medium article â€œEvolving Game of Lifeâ€ [medium.com](https://medium.com/%40tomgrek/evolving-game-of-life-neural-networks-chaos-and-complexity-94b509bc7aa8?utm_source=chatgpt.com)|
|7â€ƒGoing deeper later|CNNs + transfer learning, convolutional policy heads, evolution loops|**fast.ai Practical Deep Learning for Coders** full course [course.fast.ai](https://course.fast.ai/?utm_source=chatgpt.com)|
### About novelty search

Researchers have shown that **novelty alone can find complex, surprising solutions** even when objective-based search stalls [cs.swarthmore.edu](https://www.cs.swarthmore.edu/~meeden/DevelopmentalRobotics/lehman_ecj11.pdf?utm_source=chatgpt.com)[link.springer.com](https://link.springer.com/chapter/10.1007/978-1-4614-1770-5_3?utm_source=chatgpt.com), and that **MAP-Elites** (a grid of niches) combines novelty with quality to cover behaviour space efficiently [members.loria.fr](https://members.loria.fr/jbmouret/qd.html?utm_source=chatgpt.com)[algorithmafternoon.com](https://algorithmafternoon.com/novelty/map_elites/?utm_source=chatgpt.com).

## Key ideas in learner.py

|Name|Laymanâ€™s meaning|Code we need|
|---|---|---|
|**Behaviour descriptor**|A short numeric fingerprint that summarises the pattern after we drop the cell (e.g. â€œpopulation = 180, centre-of-mass â‰ˆ (10, 15)â€).|A small function `descriptor(grid)`|
|**Archive**|A list of all fingerprints weâ€™ve seen so far.|A global `deque` (ring buffer)|
|**Novelty score**|â€œHow far is my fingerprint from the nearest old fingerprints?â€ (big distance â‡’ novel).|Function `novelty(desc)`|
|**Total reward**|How much to reward this move when updating the net. Could be **novelty only** or **novelty + a bit of quality**.|`total_r = n_r + 0.3 * q_r`|

If you set the weight `0.3` to `0.0` you get **pure novelty** learning.

## Why gradient descent â€œlearns noveltyâ€ after this change

- **Higher total_r** â‡’ label at that square is bigger.
    
- Loss = `(pred â€“ label)Â²`, so the optimiser tries to _raise the prediction_ for that square next time.
    
- Because big labels now come from **novel** outcomes, the network is automatically nudged to choose squares that **lead to unseen patterns**.
    

Tuning knobs

|Wantâ€¦|Do this|
|---|---|
|**Pure curiosity**|`total_r = n_r` (drop the quality term).|
|**More stability, less randomness**|Increase quality weight: `total_r = n_r + 1.0 * q_r`.|
|**Bigger novelty horizon**|Roll the grid 32 steps instead of 16.|
|**Smaller archive**|`deque(maxlen=500)` â€“ faster, but less historical memory.|
## Where to learn more (beginner-friendly)

1. **10-minute video** â€œWhy Novelty Search beats Objectivesâ€ â€“ Joel Lehman (YouTube).
    
2. **Article** â€œMAP-Elites in 5 minutesâ€ â€“ AlgorithmAfternoon blog (walk-through) [algorithmafternoon.com](https://algorithmafternoon.com/novelty/map_elites/?utm_source=chatgpt.com)
    
3. **Hands-on notebook** â€“ QDax (JAX) examples: novelty, MAP-Elites, POET (GitHub).
    
4. **Survey** â€œQuality-Diversity algorithmsâ€ â€“ Mouret, 2023 (easy PDF).


#### Why we have evolution function and learning function separately
##### The two techniques are complementary

|Aspect|Neuro-evolution (**offline**)|Gradient descent (**online**)|
|---|---|---|
|**Needs labelled data?**|No â€“ scores itself in a sandbox.|Yes â€“ gets â€œstate, action, rewardâ€ from replay.|
|**Good at**|Jump-starting from random weights; escaping bad local optima; exploring weird regions.|Fast, incremental polishing; converging smoothly; working with small updates.|
|**Computational style**|Evaluate many networks in parallel, then _copy + mutate_.|Update one network a tiny bit every N seconds.|
|**When it runs**|Before you launch (or during quiet time).|While the app is live, between user clicks.|
|**Risk if used alone**|Takes CPU minutes every time you want the brain to change.|Starts from randomnessâ†’ plays terribly until enough data exists.|

By **bootstrapping with evolution** you avoid a helpless first hour.  
By **fine-tuning with online learning** you avoid freezing the interface each time you improve the model.

---

### Analogy

1. **Evolution phase** = _â€œhire a trainee who already knows the basicsâ€_ (they practised alone in a simulator).
    
2. **Learner phase** = _â€œon-the-job coachingâ€_ â€” the trainee now learns subtleties from real customers without leaving the shop.
    

---

### Could we merge them?

Technically yes, but youâ€™d either:

- **Run evolution continuously** â†’ huge CPU load and noticeable lag, or
    
- **Start with pure gradient descent** â†’ the AI would make random, boring moves until enough history accumulates.
    

Keeping the two files and algorithms separate gives you the best of both worlds with clear, beginner-friendly code boundaries:

- **`evolution.py`** â€“ run once (or occasionally) to create a solid starting model.
    
- **`learner.py`** â€“ keep running forever to make that model steadily smarter in real time.
    

That separation is all about **practicality and smooth user experience**, not about any hard technical limitation.


#### Designing Neural Net 

### How It Works in Simple Terms

## ğŸ¯ Goal

Design a **mirroring function** where the AI:

- ğŸª Observes **where and how** the human placed a cell
    
- ğŸ¨ Places a **complementary** cell, not a copy
    
- ğŸ§¬ Helps the game continue evolving, not die or stagnate
    

---

## ğŸ”§ What Does "Mirror" Mean in This Context?

We can think of mirroring as:

- ğŸ” **Geometric**: Reflecting or rotating the move (like symmetric play)
    
- ğŸ§  **Semantic**: Completing or responding to the pattern type (like finishing a glider)
    
- ğŸ§© **Relational**: Moving near the human cell but with a twist in purpose


### ğŸŸ© **Option C: Learnable Mirror Embedding (LifeNet++)**

âœ… Best long-term option  
â›” Requires training

#### How it works:

- The model learns to generate a **heatmap** over the board
    
- But the **input includes a "mirror hint"** â€” a vector derived from the human move
    

You can encode the human move in the input in 2 ways:

#### 1. **As a Spatial Mask**:

- Add a 2nd channel (64Ã—64) where only the human cell is marked
    
- The model _learns_ to focus on that area
    

#### 2. **As a Relative Vector**:

- Calculate `(dx, dy)` from human move
    
- Encourage the AI to place **within N units** of that, but not exactly the same
    

#### Training trick:

- During training, label good AI moves that:
    
    - Are **near but not same** as human
        
    - Lead to **stable + novel** future states
        

âœ… Good for:

- Long-term strategic behavior
    
- Creative, adaptive mirroring
    
- Generalization to different humans


## A design mock idea

I want to use a simple game to simulate the act of working. The game is a higher-order representation of all kinds of work. The reason why I didn't want to dive into a specific job title is that, I want to spin out varieties of basic design concepts in the first place. Using a simple, abstracted work will likely help me do that more easily.

The important point of validation is how much the design can empower people who would start from scratch, so that in a real world scenario, anyone with a little interest can jump in and start to explore a new domain of work.

The game I have in mind is Conway's Game of Life.

Game of Life is a fascinating example that's reminiscent of the actual world we live in, but on a 2D, simple-ruled, checkboard. It is reminiscent of the world in the sense that, beneath the complexity we see in nature and society, there often lies a set of simple initial rules. But the simple rules can lead to mesmerising phenomena that is hard to grasp at each single instant as a whole.

I chose Game of Life also in the hope of bridging the gap between research in Artificial Intelligence and Artificial Life. Stepping outside from human-centric view of the world, we must admit that there are different forms of intelligence that don't limit to human intelligence which the current AI is modeled after. Even focusing solely on human species, we embody far more qualities than "intelligence". These other qualities and other forms of intelligence are studied in ALife, but not as much in ML and AI related domains. Closing this gap will enable us to envision a broader range of design possibilities alongside current agentic modelsâ€”ones that may help overcome the challenges of deception, loss of user autonomy, and malicious intent in AI development.

In the interactive Game of Life, the goal for the user is to keep the variety and livelihood on the board regardless of the latest status, by placing a new dot on the board. Similar to the real world in which we face a fast-changing situation, but we (hopefully) freely choose a specific action that will (hopefully) keep the variety and the livelihood of the culture-natures on this finite planet. Sometimes the action is too small to cause anything, but we cannot know the impact for sure, at least at the instant of decision making, since the complexity is multiplied.

There are many ways AI can be added in this world. It can be another agent free of our control or a tool that does whatever we want to achieve; it can be mysterious and free, like part of the natural landscape of the Game of Life, or it can be supportive, clear and empowering. It really depends on the design.

Through this mock design, I want to experiment with different design concept to validate how different design approaches influence the user experience and most importantly, their autonomy. The design process can hopefully be shared soon.

### Todayâ€™s questions  
1. â€¦

### Experiments / code  
```python
# paste snippet


### Todayâ€™s questions  
1. â€¦

### Experiments / code  
```python
# paste snippet
